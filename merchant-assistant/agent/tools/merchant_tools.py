# -*- coding: utf-8 -*-
"""
å•†å®¶æ™ºèƒ½åŠ©æ‰‹å·¥å…·æ¨¡å—
åŒ…å«å†…å®¹ç”Ÿæˆã€ç­–ç•¥æ¨èã€CTRè¯„ä¼°ç­‰æ ¸å¿ƒå·¥å…·
"""

from typing import List, Dict, Any
import re
import jieba
import random
from langchain.tools import tool

# å…¨å±€LLMå®ä¾‹ï¼Œç”±MerchantAssistantAgentè®¾ç½®
_current_llm = None

def set_llm_instance(llm):
    """è®¾ç½®å½“å‰LLMå®ä¾‹"""
    global _current_llm
    _current_llm = llm

def get_llm_instance():
    """è·å–å½“å‰LLMå®ä¾‹"""
    return _current_llm


def preprocess_product_info(product_info: str) -> dict:
    """é¢„å¤„ç†å•†å“ä¿¡æ¯ï¼Œæå–å…³é”®è¦ç´ """
    import re
    
    processed = {
        "original": product_info,
        "product_type": "",
        "color": "",
        "season": "",
        "price": "",
        "price_range": "",
        "key_features": [],
        "keywords": []
    }
    
    # æå–å•†å“ç±»å‹
    product_types = ["è¿è¡£è£™", "Tæ¤", "è¡¬è¡«", "è£¤å­", "è£™å­", "å¤–å¥—", "é‹å­", "åŒ…åŒ…", "æ‰‹æœº", "ç”µè„‘", "è€³æœº", "å£çº¢", "é¢è†œ", "æŠ¤è‚¤å“"]
    for ptype in product_types:
        if ptype in product_info:
            processed["product_type"] = ptype
            break
    
    # æå–é¢œè‰²
    colors = ["ç²‰è‰²", "çº¢è‰²", "è“è‰²", "é»‘è‰²", "ç™½è‰²", "ç°è‰²", "ç»¿è‰²", "é»„è‰²", "ç´«è‰²", "æ©™è‰²"]
    for color in colors:
        if color in product_info or color[:-1] in product_info:
            processed["color"] = color
            break
    
    # æå–å­£èŠ‚
    seasons = ["æ˜¥å­£", "å¤å­£", "ç§‹å­£", "å†¬å­£", "æ˜¥", "å¤", "ç§‹", "å†¬"]
    for season in seasons:
        if season in product_info:
            processed["season"] = season
            break
    
    # æå–ä»·æ ¼
    price_match = re.search(r'(\d+)å…ƒ', product_info)
    if price_match:
        price = int(price_match.group(1))
        processed["price"] = f"{price}å…ƒ"
        if price < 50:
            processed["price_range"] = "è¶…ä½ä»·"
        elif price < 100:
            processed["price_range"] = "ä½ä»·ä½"
        elif price < 300:
            processed["price_range"] = "ä¸­ç­‰ä»·ä½"
        elif price < 800:
            processed["price_range"] = "ä¸­é«˜ä»·ä½"
        else:
            processed["price_range"] = "é«˜ç«¯ä»·ä½"
    
    # æå–å…³é”®ç‰¹å¾
    features = ["æ–°æ¬¾", "çƒ­é”€", "é™é‡", "è¿›å£", "çº¯æ£‰", "çœŸä¸", "é˜²æ°´", "é€æ°”", "æ˜¾ç˜¦", "ç™¾æ­", "æ—¶å°š", "ç»å…¸"]
    for feature in features:
        if feature in product_info:
            processed["key_features"].append(feature)
    
    # ä½¿ç”¨jiebaæå–å…³é”®è¯
    keywords = list(jieba.cut(product_info))
    processed["keywords"] = [k for k in keywords if len(k) > 1 and k not in ['ï¼Œ', 'ã€‚', 'ã€', 'çš„', 'æ˜¯', 'å’Œ', 'ä¸', 'é€‚åˆ']]
    
    return processed

def evaluate_title_quality(title: str, product_info: str, target_audience: str) -> dict:
    """è¯„ä¼°æ ‡é¢˜è´¨é‡ï¼Œç”¨äºå†³å®šæ˜¯å¦éœ€è¦äºŒæ¬¡ä¼˜åŒ–"""
    score = 0
    issues = []
    recommendations = []
    
    # 1. é•¿åº¦æ£€æŸ¥ (æƒé‡: 20åˆ†)
    length = len(title)
    if 15 <= length <= 25:
        score += 20
    elif 12 <= length <= 30:
        score += 15
        if length < 15:
            issues.append("æ ‡é¢˜è¿‡çŸ­")
            recommendations.append("å¢åŠ ä¿®é¥°è¯æˆ–å–ç‚¹æè¿°")
        else:
            issues.append("æ ‡é¢˜è¿‡é•¿")
            recommendations.append("ç²¾ç®€è¡¨è¾¾ï¼Œçªå‡ºæ ¸å¿ƒå–ç‚¹")
    else:
        score += 5
        issues.append("æ ‡é¢˜é•¿åº¦ä¸åˆè§„")
        recommendations.append("æ§åˆ¶åœ¨15-25å­—ç¬¦é—´")
    
    # 2. æ ¼å¼æ£€æŸ¥ (æƒé‡: 15åˆ†)
    if 'ï¼Œ' in title or ',' in title:
        issues.append("ä½¿ç”¨äº†é€—å·åˆ†éš”")
        recommendations.append("ç”¨ç©ºæ ¼æˆ–è¿è¯æ›¿ä»£é€—å·")
    else:
        score += 15
    
    # 3. å—ä¼—åŒ¹é…åº¦æ£€æŸ¥ (æƒé‡: 25åˆ†)
    audience_keywords = {
        "å¹´è½»å¥³æ€§": ["å°‘å¥³å¿ƒ", "ç”œç¾", "ä»™å¥³", "å°æ¸…æ–°", "ç½‘çº¢", "ç§è‰", "å¿ƒåŠ¨", "çˆ±äº†", "å¯çˆ±", "èŒ"],
        "ä¸­å¹´å¥³æ€§": ["ä¼˜é›…", "çŸ¥æ€§", "èˆ’é€‚", "ç™¾æ­", "ç»å…¸", "å“è´¨", "æ°”è´¨", "ç²¾è‡´", "æ¸©æŸ”"],
        "å¹´è½»ç”·æ€§": ["æ½®æµ", "é…·ç‚«", "ç§‘æŠ€", "ä¸ªæ€§", "æ€§èƒ½", "ä¸“ä¸š", "ç»™åŠ›", "å¸…æ°”"],
        "å­¦ç”Ÿ": ["å­¦ç”Ÿ", "æ€§ä»·æ¯”", "å®ç”¨", "çœé’±", "å¿…å¤‡", "è¶…å€¼", "ä¾¿å®œ", "åˆ’ç®—"]
    }
    
    target_words = audience_keywords.get(target_audience, [])
    found_keywords = sum(1 for word in target_words if word in title)
    if found_keywords >= 1:
        score += 25
    elif found_keywords == 0:
        score += 10
        issues.append("ç¼ºä¹å—ä¼—ç‰¹è‰²è¯æ±‡")
        recommendations.append(f"å»ºè®®èå…¥{target_audience}å–œå¥½çš„è¯æ±‡")
    
    # 4. å•†å“ä¿¡æ¯åŒ¹é…åº¦ (æƒé‡: 20åˆ†)
    processed_info = preprocess_product_info(product_info)
    product_elements = [processed_info['product_type'], processed_info['color'], processed_info['season']]
    product_elements = [elem for elem in product_elements if elem]
    
    matched_elements = sum(1 for elem in product_elements if elem in title)
    if matched_elements >= 2:
        score += 20
    elif matched_elements == 1:
        score += 15
    else:
        score += 5
        issues.append("å•†å“ä¿¡æ¯èå…¥ä¸è¶³")
        recommendations.append("å¢åŠ å•†å“æ ¸å¿ƒç‰¹å¾æè¿°")
    
    # 5. å¸å¼•åŠ›æ£€æŸ¥ (æƒé‡: 20åˆ†)
    attractive_words = ["é™æ—¶", "ç‰¹æƒ ", "æ–°æ¬¾", "çƒ­é”€", "çˆ†æ¬¾", "å¿…å…¥", "æ¨è", "ç²¾é€‰", "ä¼˜é€‰", "æŠ¢è´­"]
    emotion_symbols = ["ã€", "ã€‘", "ğŸ”¥", "ğŸ’•", "âœ¨", "ğŸŒ¸", "â­", "ğŸ‘‘", "ğŸ’"]
    
    attractive_count = sum(1 for word in attractive_words if word in title)
    symbol_count = sum(1 for symbol in emotion_symbols if symbol in title)
    
    if attractive_count >= 1 or symbol_count >= 1:
        score += 20
    else:
        score += 10
        issues.append("ç¼ºä¹å¸å¼•åŠ›å…ƒç´ ")
        recommendations.append("æ·»åŠ ä¿ƒé”€è¯æ±‡æˆ–æƒ…æ„Ÿç¬¦å·")
    
    # è®¡ç®—æœ€ç»ˆè¯„åˆ†
    final_score = min(score / 100, 1.0)
    
    return {
        "score": final_score,
        "grade": "ä¼˜ç§€" if final_score >= 0.8 else "è‰¯å¥½" if final_score >= 0.6 else "ä¸€èˆ¬" if final_score >= 0.4 else "éœ€æ”¹è¿›",
        "issues": issues,
        "recommendations": recommendations,
        "need_optimization": final_score < 0.75
    }

def optimize_title_with_feedback(original_title: str, evaluation: dict, product_info: str, style: str, target_audience: str) -> str:
    """åŸºäºè¯„ä¼°ç»“æœä¼˜åŒ–æ ‡é¢˜"""
    llm = get_llm_instance()
    
    if llm and llm.__class__.__name__ != 'MockLLM':
        processed_info = preprocess_product_info(product_info)
        audience_profile = get_audience_profile(target_audience)
        
        optimization_prompt = f"""ä½ æ˜¯æ ‡é¢˜ä¼˜åŒ–ä¸“å®¶ï¼Œéœ€è¦æ ¹æ®è´¨é‡è¯„ä¼°ç»“æœä¼˜åŒ–ç”µå•†æ ‡é¢˜ã€‚

ã€åŸæ ‡é¢˜ã€‘
{original_title}

ã€è´¨é‡è¯„ä¼°ç»“æœã€‘
- å½“å‰è¯„åˆ†ï¼š{evaluation['score']:.2f} ({evaluation['grade']})
- å‘ç°é—®é¢˜ï¼š{', '.join(evaluation['issues']) if evaluation['issues'] else 'æ— æ˜æ˜¾é—®é¢˜'}
- ä¼˜åŒ–å»ºè®®ï¼š{', '.join(evaluation['recommendations']) if evaluation['recommendations'] else 'ç»§ç»­ä¿æŒ'}

ã€å•†å“ä¿¡æ¯ã€‘
- å•†å“ç±»å‹ï¼š{processed_info['product_type']}
- æ ¸å¿ƒä¿¡æ¯ï¼š{processed_info['original']}
- ç›®æ ‡ç”¨æˆ·ï¼š{target_audience} (åå¥½è¯æ±‡ï¼š{', '.join(audience_profile['å…³é”®è¯'][:5])})
- é£æ ¼è¦æ±‚ï¼š{style}

ã€ä¼˜åŒ–è¦æ±‚ã€‘
1. é’ˆå¯¹æ€§è§£å†³ä¸Šè¿°è´¨é‡é—®é¢˜
2. ä¿æŒ{style}é£æ ¼ç‰¹è‰²
3. é•¿åº¦æ§åˆ¶åœ¨15-25å­—ç¬¦
4. é¿å…ä½¿ç”¨é€—å·åˆ†éš”
5. å¢å¼º{target_audience}ç¾¤ä½“çš„å¸å¼•åŠ›

è¯·è¾“å‡ºä¼˜åŒ–åçš„æ ‡é¢˜ï¼ˆåªè¾“å‡ºæ ‡é¢˜ï¼Œä¸è¦è§£é‡Šï¼‰ï¼š"""
        
        try:
            optimized_title = llm.invoke(optimization_prompt)
            # æ¸…ç†è¾“å‡º
            optimized_title = optimized_title.strip().replace('\n', ' ').replace('\r', '')
            
            # ç§»é™¤å¯èƒ½çš„å‰ç¼€
            prefixes = ['ä¼˜åŒ–åæ ‡é¢˜ï¼š', 'æ ‡é¢˜ï¼š', 'å»ºè®®ï¼š', 'ç­”ï¼š']
            for prefix in prefixes:
                if optimized_title.startswith(prefix):
                    optimized_title = optimized_title[len(prefix):].strip()
            
            if (optimized_title.startswith('"') and optimized_title.endswith('"')):
                optimized_title = optimized_title[1:-1]
                
            return optimized_title
        except Exception as e:
            print(f"æ ‡é¢˜ä¼˜åŒ–å¤±è´¥: {e}")
            return original_title
    
    return original_title

def get_audience_profile(target_audience: str) -> dict:
    """è·å–ç›®æ ‡å—ä¼—ç”»åƒ"""
    profiles = {
        "å¹´è½»å¥³æ€§": {
            "å¹´é¾„": "18-30å²",
            "ç‰¹ç‚¹": "è¿½æ±‚æ—¶å°šã€ä¸ªæ€§ï¼Œæ³¨é‡é¢œå€¼å’Œç¤¾äº¤å±æ€§",
            "è¯­è¨€é£æ ¼": "æ´»æ³¼ã€å¯çˆ±ã€æœ‰è¶£",
            "å…³é”®è¯": ["å°‘å¥³å¿ƒ", "ç”œç¾", "ä»™å¥³", "å°æ¸…æ–°", "ç½‘çº¢åŒæ¬¾", "ç§è‰", "å¿ƒåŠ¨", "çˆ±äº†"],
            "è´­ä¹°åŠ¨æœº": "é¢œå€¼ã€æ½®æµã€ç¤¾äº¤åˆ†äº«",
            "ä»·æ ¼æ•æ„Ÿåº¦": "ä¸­ç­‰"
        },
        "ä¸­å¹´å¥³æ€§": {
            "å¹´é¾„": "30-50å²",
            "ç‰¹ç‚¹": "æ³¨é‡å“è´¨å’Œå®ç”¨æ€§ï¼Œæœ‰ä¸€å®šæ¶ˆè´¹èƒ½åŠ›",
            "è¯­è¨€é£æ ¼": "ä¼˜é›…ã€çŸ¥æ€§ã€å®ç”¨",
            "å…³é”®è¯": ["ä¼˜é›…", "çŸ¥æ€§", "èˆ’é€‚", "ç™¾æ­", "ç»å…¸", "å“è´¨", "æ°”è´¨", "ç²¾è‡´"],
            "è´­ä¹°åŠ¨æœº": "å“è´¨ã€å®ç”¨æ€§ã€æ€§ä»·æ¯”",
            "ä»·æ ¼æ•æ„Ÿåº¦": "ä½"
        },
        "å¹´è½»ç”·æ€§": {
            "å¹´é¾„": "18-35å²",
            "ç‰¹ç‚¹": "è¿½æ±‚ä¸ªæ€§å’Œç§‘æŠ€æ„Ÿï¼Œæ³¨é‡æ€§èƒ½",
            "è¯­è¨€é£æ ¼": "é…·ç‚«ã€ä¸“ä¸šã€ç›´æ¥",
            "å…³é”®è¯": ["æ½®æµ", "é…·ç‚«", "ç§‘æŠ€", "ä¸ªæ€§", "æ€§èƒ½", "ä¸“ä¸š", "ç»™åŠ›"],
            "è´­ä¹°åŠ¨æœº": "æ€§èƒ½ã€ç§‘æŠ€æ„Ÿã€ä¸ªæ€§è¡¨è¾¾",
            "ä»·æ ¼æ•æ„Ÿåº¦": "ä¸­ç­‰"
        },
        "å­¦ç”Ÿ": {
            "å¹´é¾„": "16-25å²",
            "ç‰¹ç‚¹": "é¢„ç®—æœ‰é™ï¼Œæ³¨é‡æ€§ä»·æ¯”",
            "è¯­è¨€é£æ ¼": "å¹´è½»ã€æ´»æ³¼ã€å®æƒ ",
            "å…³é”®è¯": ["å­¦ç”Ÿä¸“äº«", "æ€§ä»·æ¯”", "å®ç”¨", "çœé’±", "å¿…å¤‡", "è¶…å€¼"],
            "è´­ä¹°åŠ¨æœº": "æ€§ä»·æ¯”ã€å®ç”¨æ€§",
            "ä»·æ ¼æ•æ„Ÿåº¦": "é«˜"
        },
        "é€šç”¨": {
            "å¹´é¾„": "å…¨å¹´é¾„",
            "ç‰¹ç‚¹": "å¤§ä¼—åŒ–éœ€æ±‚",
            "è¯­è¨€é£æ ¼": "é€šä¿—æ˜“æ‡‚ã€äº²å’Œ",
            "å…³é”®è¯": ["ç²¾é€‰", "çƒ­é”€", "æ¨è", "ä¼˜è´¨", "å¥½è¯„", "å€¼å¾—"],
            "è´­ä¹°åŠ¨æœº": "å“è´¨ã€å£ç¢‘",
            "ä»·æ ¼æ•æ„Ÿåº¦": "ä¸­ç­‰"
        }
    }
    return profiles.get(target_audience, profiles["é€šç”¨"])

@tool
def generate_product_title(product_info: str, style: str = "çˆ†æ¬¾", target_audience: str = "é€šç”¨") -> str:
    """
    æ ¹æ®å•†å“ä¿¡æ¯ç”Ÿæˆæ¨èæ ‡é¢˜
    
    Args:
        product_info: å•†å“ä¿¡æ¯ï¼ŒåŒ…å«ç±»ç›®ã€å±æ€§ã€ä»·æ ¼ç­‰
        style: æ–‡æ¡ˆé£æ ¼ï¼Œå¦‚"çˆ†æ¬¾"ã€"ç®€çº¦"ã€"é«˜ç«¯"ç­‰
        target_audience: ç›®æ ‡å—ä¼—ï¼Œå½±å“æ ‡é¢˜ç”¨è¯å’Œè¡¨è¾¾æ–¹å¼
        
    Returns:
        ç”Ÿæˆçš„å•†å“æ ‡é¢˜
    """
    
    llm = get_llm_instance()
    
    # é¢„å¤„ç†å•†å“ä¿¡æ¯
    processed_info = preprocess_product_info(product_info)
    audience_profile = get_audience_profile(target_audience)
    
    # å¦‚æœæœ‰çœŸå®çš„LLMï¼Œä½¿ç”¨LLMç”Ÿæˆ
    if llm and llm.__class__.__name__ != 'MockLLM':
        # æ„å»ºå¢å¼ºçš„prompt
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±ç”µå•†æ–‡æ¡ˆä¸“å®¶ï¼Œæ‹¥æœ‰10å¹´+çš„çˆ†æ¬¾æ ‡é¢˜åˆ›ä½œç»éªŒã€‚

ã€å•†å“åˆ†æã€‘
- å•†å“ç±»å‹ï¼š{processed_info['product_type'] or 'æœªè¯†åˆ«'}
- æ ¸å¿ƒä¿¡æ¯ï¼š{processed_info['original']}
- é¢œè‰²ç‰¹å¾ï¼š{processed_info['color'] or 'æ— '}
- å­£èŠ‚å±æ€§ï¼š{processed_info['season'] or 'æ— '}
- ä»·æ ¼å®šä½ï¼š{processed_info['price_range'] or 'æœªçŸ¥'}
- å…³é”®å–ç‚¹ï¼š{', '.join(processed_info['key_features']) or 'å¾…æŒ–æ˜'}

ã€ç›®æ ‡ç”¨æˆ·ç”»åƒã€‘
- ç”¨æˆ·ç¾¤ä½“ï¼š{target_audience} ({audience_profile['å¹´é¾„']})
- ç”¨æˆ·ç‰¹ç‚¹ï¼š{audience_profile['ç‰¹ç‚¹']}
- è¯­è¨€åå¥½ï¼š{audience_profile['è¯­è¨€é£æ ¼']}
- è´­ä¹°åŠ¨æœºï¼š{audience_profile['è´­ä¹°åŠ¨æœº']}
- ä»·æ ¼æ•æ„Ÿåº¦ï¼š{audience_profile['ä»·æ ¼æ•æ„Ÿåº¦']}

ã€æ–‡æ¡ˆé£æ ¼è¦æ±‚ã€‘
- é£æ ¼å®šä½ï¼š{style}
- å­—ç¬¦é•¿åº¦ï¼š15-25å­—ç¬¦
- è¯­è¨€é£æ ¼ï¼šç¬¦åˆ{target_audience}çš„è¡¨è¾¾ä¹ æƒ¯
- å¿…é¡»é¿å…ï¼šé€—å·åˆ†éš”å…³é”®è¯

ã€åˆ›ä½œè¦æ±‚ã€‘
1. ä»ç”¨æˆ·ç—›ç‚¹å‡ºå‘ï¼Œçªå‡ºå•†å“èƒ½è§£å†³çš„é—®é¢˜
2. èå…¥{audience_profile['å…³é”®è¯'][:3]}ç­‰ç¬¦åˆç”¨æˆ·ç¾¤ä½“çš„è¯æ±‡
3. æ ¹æ®ä»·æ ¼å®šä½é€‰æ‹©åˆé€‚çš„è¥é”€ç­–ç•¥
4. ç¡®ä¿æ ‡é¢˜å…·æœ‰ç‚¹å‡»å†²åŠ¨å’Œè´­ä¹°æ¬²æœ›
5. ç¬¦åˆç”µå•†å¹³å°æ ‡é¢˜è§„èŒƒ

è¯·åŸºäºä»¥ä¸Šåˆ†æï¼Œåˆ›ä½œä¸€ä¸ª{style}é£æ ¼çš„ä¸“ä¸šæ ‡é¢˜ï¼š"""
        
        try:
            title = llm.invoke(prompt)
            # æ¸…ç†è¾“å‡º
            title = title.strip().replace('\n', ' ').replace('\r', '')
            
            # ç§»é™¤å¯èƒ½çš„å‰ç¼€
            prefixes = ['æ ‡é¢˜ï¼š', 'å»ºè®®æ ‡é¢˜ï¼š', 'æ¨èæ ‡é¢˜ï¼š', 'æ ‡é¢˜:', 'ç­”:', 'ç­”ï¼š']
            for prefix in prefixes:
                if title.startswith(prefix):
                    title = title[len(prefix):].strip()
            
            # ç§»é™¤å¼•å·
            if (title.startswith('"') and title.endswith('"')) or (title.startswith('"') and title.endswith('"')):
                title = title[1:-1]
            
            # é•¿åº¦æ§åˆ¶
            if len(title) > 30:
                title = title[:28] + "..."
            
            # è´¨é‡è¯„ä¼°å’ŒäºŒæ¬¡ä¼˜åŒ–
            evaluation = evaluate_title_quality(title, product_info, target_audience)
            
            if evaluation['need_optimization']:
                print(f"æ ‡é¢˜è´¨é‡è¯„åˆ†: {evaluation['score']:.2f} ({evaluation['grade']}) - è¿›è¡ŒäºŒæ¬¡ä¼˜åŒ–")
                optimized_title = optimize_title_with_feedback(title, evaluation, product_info, style, target_audience)
                
                # éªŒè¯ä¼˜åŒ–æ•ˆæœ
                new_evaluation = evaluate_title_quality(optimized_title, product_info, target_audience)
                if new_evaluation['score'] > evaluation['score']:
                    print(f"ä¼˜åŒ–æˆåŠŸ: {evaluation['score']:.2f} -> {new_evaluation['score']:.2f}")
                    return optimized_title
                else:
                    print("ä¼˜åŒ–æ•ˆæœä¸ä½³ï¼Œä½¿ç”¨åŸæ ‡é¢˜")
                    return title
            else:
                print(f"æ ‡é¢˜è´¨é‡è‰¯å¥½: {evaluation['score']:.2f} ({evaluation['grade']})")
                return title
                
        except Exception as e:
            print(f"LLMè°ƒç”¨å¤±è´¥: {e}")
            pass
    
    # å›é€€åˆ°è§„åˆ™å¼•æ“æ¨¡å¼
    # æ ¹æ®ç›®æ ‡å—ä¼—å®šä¹‰è¯æ±‡åº“
    audience_config = {
        "å¹´è½»å¥³æ€§": {
            "å‰ç¼€": ["ğŸŒ¸", "ğŸ’•", "ã€å°‘å¥³å¿ƒã€‘", "ã€ç”œç¾ã€‘"],
            "ä¿®é¥°": ["å°æ¸…æ–°", "ä»™å¥³èŒƒ", "ç”œç¾", "å°‘å¥³å¿ƒ"],
            "åç¼€": ["å¿ƒåŠ¨å¿…å…¥", "ç§è‰äº†", "çˆ±äº†çˆ±äº†"]
        },
        "ä¸­å¹´å¥³æ€§": {
            "å‰ç¼€": ["ã€ä¼˜é›…ã€‘", "ã€ç»å…¸ã€‘", "ğŸŒ¹"],
            "ä¿®é¥°": ["çŸ¥æ€§", "ä¼˜é›…", "èˆ’é€‚", "ç™¾æ­"],
            "åç¼€": ["å“è´¨ä¹‹é€‰", "æ°”è´¨ä¼˜é€‰", "ç²¾è‡´ç”Ÿæ´»"]
        },
        "å¹´è½»ç”·æ€§": {
            "å‰ç¼€": ["ğŸ”¥", "ã€æ½®æµã€‘", "ã€é…·ç‚«ã€‘"],
            "ä¿®é¥°": ["æ½®æµ", "ä¸ªæ€§", "é…·ç‚«", "æ—¶å°š"],
            "åç¼€": ["ç‚¸è£‚æ¨è", "ç»™åŠ›å¥½ç‰©", "æ½®ç”·å¿…å¤‡"]
        },
        "å­¦ç”Ÿ": {
            "å‰ç¼€": ["ã€å­¦ç”Ÿä¸“äº«ã€‘", "ğŸ’°", "ã€è¶…å€¼ã€‘"],
            "ä¿®é¥°": ["å®ç”¨", "æ€§ä»·æ¯”", "å­¦ç”Ÿæ¬¾", "æ ¡å›­"],
            "åç¼€": ["å­¦ç”Ÿå¿…å¤‡", "è¶…å€¼å¥½ç‰©", "çœé’±é¦–é€‰"]
        },
        "é€šç”¨": {
            "å‰ç¼€": ["ã€ç²¾é€‰ã€‘", "â­", "ã€æ¨èã€‘"],
            "ä¿®é¥°": ["ä¼˜è´¨", "ç²¾é€‰", "çƒ­é”€", "æ¨è"],
            "åç¼€": ["å“è´¨ä¿è¯", "å€¼å¾—æ‹¥æœ‰", "å¥½è¯„å¦‚æ½®"]
        }
    }
    
    config = audience_config.get(target_audience, audience_config["é€šç”¨"])
    
    # æå–å•†å“å…³é”®ä¿¡æ¯
    keywords = list(jieba.cut(product_info))
    keywords = [k for k in keywords if len(k) > 1 and k not in ['ï¼Œ', 'ã€‚', 'ã€', 'çš„', 'æ˜¯', 'å’Œ', 'ä¸']]
    
    # è¯†åˆ«å•†å“ç±»å‹
    product_name = ""
    product_types = ["è¿è¡£è£™", "Tæ¤", "è¡¬è¡«", "è£¤å­", "è£™å­", "å¤–å¥—", "é‹å­", "åŒ…åŒ…", "æ‰‹æœº", "ç”µè„‘", "è€³æœº", "å£çº¢", "é¢è†œ", "æŠ¤è‚¤å“"]
    for ptype in product_types:
        if ptype in product_info:
            product_name = ptype
            break
    
    if not product_name and keywords:
        product_name = keywords[0]
    
    # æå–ç‰¹å¾
    features = []
    if "ç²‰è‰²" in product_info:
        features.append("ç²‰è‰²")
    if "å¤å­£" in product_info or "å¤å¤©" in product_info:
        features.append("å¤å­£")
    if "æ–°æ¬¾" in product_info:
        features.append("æ–°æ¬¾")
    if "129" in product_info:
        features.append("è¶…å€¼ä»·")
    
    # æ ¹æ®é£æ ¼ç”Ÿæˆæ ‡é¢˜
    if style == "çˆ†æ¬¾":
        prefix = random.choice(config["å‰ç¼€"])
        modifier = random.choice(config["ä¿®é¥°"])
        suffix = random.choice(config["åç¼€"])
        title = f"{prefix}{modifier}{product_name} {' '.join(features[:2])} {suffix}"
    elif style == "ç®€çº¦":
        modifier = random.choice(config["ä¿®é¥°"])
        title = f"{modifier}{product_name} {' '.join(features[:2])}"
    else:  # é«˜ç«¯
        title = f"è‡»é€‰{product_name} {' '.join(features[:1])} åŒ å¿ƒå“è´¨"
    
    # æ¸…ç†æ ‡é¢˜
    title = re.sub(r'\s+', ' ', title).strip()
    
    return title


@tool  
def suggest_strategy(product_type: str, target_audience: str = "é€šç”¨", budget: str = "ä¸­ç­‰", product_info: str = "") -> str:
    """
    æ ¹æ®å•†å“ç±»å‹å’Œç›®æ ‡å—ä¼—æ¨èè¥é”€ç­–ç•¥
    
    Args:
        product_type: å•†å“ç±»å‹ï¼Œå¦‚"æœè£…"ã€"æ•°ç "ã€"ç¾å¦†"ç­‰
        target_audience: ç›®æ ‡å—ä¼—ï¼Œå¦‚"å¹´è½»å¥³æ€§"ã€"ä¸­å¹´ç”·æ€§"ã€"å­¦ç”Ÿ"ç­‰
        budget: é¢„ç®—æ°´å¹³ï¼Œå¦‚"ä½"ã€"ä¸­ç­‰"ã€"é«˜"
        product_info: å•†å“è¯¦ç»†ä¿¡æ¯ï¼Œç”¨äºä¸ªæ€§åŒ–å»ºè®®
        
    Returns:
        æ¨èçš„è¥é”€ç­–ç•¥
    """
    
    llm = get_llm_instance()
    
    # å¦‚æœæœ‰çœŸå®çš„LLMï¼Œä½¿ç”¨LLMç”Ÿæˆè¯¦ç»†ç­–ç•¥
    if llm and llm.__class__.__name__ != 'MockLLM':
        # é¢„å¤„ç†å•†å“ä¿¡æ¯
        processed_info = preprocess_product_info(product_info)
        audience_profile = get_audience_profile(target_audience)
        
        # æ„å»ºå¢å¼ºçš„prompt
        prompt = f"""ä½ æ˜¯ä¸€ä½æ‹¥æœ‰15å¹´ç»éªŒçš„ç”µå•†è¥é”€æˆ˜ç•¥ä¸“å®¶ï¼Œæ“…é•¿ä¸ºä¸åŒå“ç±»å’Œå—ä¼—åˆ¶å®šç²¾å‡†è¥é”€ç­–ç•¥ã€‚

ã€é¡¹ç›®èƒŒæ™¯åˆ†æã€‘
å•†å“è¯¦ç»†ä¿¡æ¯ï¼š
- åŸºç¡€ä¿¡æ¯ï¼š{processed_info['original']}
- å•†å“ç±»å‹ï¼š{processed_info['product_type'] or product_type}
- é¢œè‰²ç‰¹å¾ï¼š{processed_info['color'] or 'æ— '}
- å­£èŠ‚å±æ€§ï¼š{processed_info['season'] or 'æ— '}
- ä»·æ ¼å®šä½ï¼š{processed_info['price_range']} ({processed_info['price']})
- æ ¸å¿ƒå–ç‚¹ï¼š{', '.join(processed_info['key_features']) or 'éœ€è¦æŒ–æ˜'}

ã€ç›®æ ‡ç”¨æˆ·æ·±åº¦ç”»åƒã€‘
- ç”¨æˆ·ç¾¤ä½“ï¼š{target_audience} ({audience_profile['å¹´é¾„']})
- è¡Œä¸ºç‰¹å¾ï¼š{audience_profile['ç‰¹ç‚¹']}
- æ²Ÿé€šåå¥½ï¼š{audience_profile['è¯­è¨€é£æ ¼']}
- è´­ä¹°é©±åŠ¨ï¼š{audience_profile['è´­ä¹°åŠ¨æœº']}
- ä»·æ ¼æ•æ„Ÿåº¦ï¼š{audience_profile['ä»·æ ¼æ•æ„Ÿåº¦']}
- å¸¸ç”¨è¯æ±‡ï¼š{', '.join(audience_profile['å…³é”®è¯'])}

ã€é¢„ç®—çº¦æŸã€‘
- é¢„ç®—çº§åˆ«ï¼š{budget}
- é¢„ç®—ç‰¹ç‚¹ï¼š{'éœ€è¦ç²¾ç»†åŒ–è¿è¥ï¼Œé‡ç‚¹ROI' if budget == 'ä½' else 'å¯è¿›è¡Œå¤šæ¸ é“æŠ•æ”¾ï¼Œé€‚åº¦è¯•é”™' if budget == 'ä¸­ç­‰' else 'å¯å…¨æ¸ é“è¦†ç›–ï¼Œå“ç‰ŒåŒ–è¿è¥'}

ã€ç­–ç•¥åˆ¶å®šè¦æ±‚ã€‘
åŸºäºä»¥ä¸Šæ·±åº¦åˆ†æï¼Œè¯·åˆ¶å®šä¸€ä»½ä¸“ä¸šçš„è¥é”€æ‰§è¡Œæ–¹æ¡ˆï¼ŒåŒ…å«ä»¥ä¸‹7ä¸ªç»´åº¦ï¼š

1. **ç”¨æˆ·æ´å¯Ÿä¸ç—›ç‚¹åˆ†æ** (100å­—)
   - æ·±åº¦åˆ†æç›®æ ‡ç”¨æˆ·çš„æ ¸å¿ƒéœ€æ±‚å’Œè´­ä¹°éšœç¢
   - è¯†åˆ«å•†å“èƒ½è§£å†³çš„å…·ä½“é—®é¢˜

2. **æ¸ é“ç»„åˆç­–ç•¥** (120å­—)
   - åŸºäºç”¨æˆ·ç”»åƒæ¨è3-4ä¸ªç²¾å‡†æ¸ é“
   - è¯´æ˜æ¯ä¸ªæ¸ é“çš„ä½œç”¨å’Œé¢„æœŸæ•ˆæœ
   - è€ƒè™‘é¢„ç®—çº¦æŸè¿›è¡Œä¼˜å…ˆçº§æ’åº

3. **å†…å®¹è¥é”€ç­–ç•¥** (150å­—)
   - å…·ä½“çš„å†…å®¹åˆ›ä½œæ–¹å‘å’Œä¸»é¢˜
   - é’ˆå¯¹ä¸åŒæ¸ é“çš„å†…å®¹å½¢å¼å»ºè®®
   - èå…¥ç”¨æˆ·åå¥½çš„è¯æœ¯å’Œè¡¨è¾¾æ–¹å¼

4. **ä¿ƒé”€ä¸è½¬åŒ–ç­–ç•¥** (100å­—)
   - ç»“åˆä»·æ ¼å®šä½è®¾è®¡ä¿ƒé”€æ–¹æ¡ˆ
   - æä¾›å…·ä½“çš„ä¼˜æƒ ç­–ç•¥å’Œæ—¶æœºå®‰æ’

5. **é¢„ç®—åˆ†é…ä¸æŠ•æ”¾ç­–ç•¥** (80å­—)
   - å„æ¸ é“çš„é¢„ç®—æ¯”ä¾‹å»ºè®®
   - æŠ•æ”¾èŠ‚å¥å’Œé‡ç‚¹æ—¶æ®µå®‰æ’

6. **æ‰§è¡Œæ—¶é—´çº¿** (100å­—)
   - 4-6å‘¨çš„è¯¦ç»†æ‰§è¡Œè®¡åˆ’
   - å…³é”®èŠ‚ç‚¹å’Œé‡Œç¨‹ç¢‘è®¾ç½®

7. **æ•ˆæœç›‘æ§ä¸ä¼˜åŒ–** (80å­—)
   - å…³é”®æŒ‡æ ‡å®šä¹‰å’Œç›‘æ§æ–¹æ³•
   - ä¼˜åŒ–è°ƒæ•´çš„åˆ¤æ–­æ ‡å‡†

ã€è¾“å‡ºè¦æ±‚ã€‘
- æ€»å­—æ•°æ§åˆ¶åœ¨750å­—å·¦å³
- æ¯ä¸ªç»´åº¦éƒ½è¦å…·ä½“å¯æ‰§è¡Œï¼Œé¿å…ç©ºæ´æ¦‚å¿µ
- ç´§å¯†ç»“åˆå•†å“ç‰¹ç‚¹å’Œç”¨æˆ·ç”»åƒ
- è¯­è¨€ä¸“ä¸šä½†æ˜“æ‡‚ï¼Œé€»è¾‘æ¸…æ™°

è¯·åŸºäºä»¥ä¸Šåˆ†ææ¡†æ¶ï¼Œè¾“å‡ºå®Œæ•´çš„è¥é”€ç­–ç•¥æ–¹æ¡ˆï¼š"""
        
        try:
            strategy = llm.invoke(prompt)
            return strategy.strip()
        except Exception as e:
            print(f"è¥é”€ç­–ç•¥LLMè°ƒç”¨å¤±è´¥: {e}")
            pass
    
    # å›é€€åˆ°ç®€åŒ–çš„ç­–ç•¥å»ºè®®
    basic_strategies = {
        "æœè£…": {
            "å¹´è½»å¥³æ€§": "å»ºè®®åœ¨å°çº¢ä¹¦å’ŒæŠ–éŸ³æŠ•æ”¾ï¼Œé‡ç‚¹å±•ç¤ºç©¿æ­æ•ˆæœï¼Œé…åˆæ—¶å°šåšä¸»åˆä½œ",
            "ä¸­å¹´å¥³æ€§": "ä¸»æ‰“å“è´¨å’Œå®ç”¨æ€§ï¼Œåœ¨å°çº¢ä¹¦æŠ•æ”¾ï¼Œå¼ºè°ƒèˆ’é€‚å’Œç™¾æ­",
            "å­¦ç”Ÿ": "çªå‡ºæ€§ä»·æ¯”å’Œæ ¡å›­æ—¶å°šï¼Œåœ¨Bç«™å’Œå¾®ä¿¡ç¾¤æ¨å¹¿"
        },
        "æ•°ç ": {
            "å¹´è½»ç”·æ€§": "åœ¨Bç«™å’ŒçŸ¥ä¹æŠ•æ”¾æŠ€æœ¯æµ‹è¯„å†…å®¹ï¼Œå¼ºè°ƒæ€§èƒ½å‚æ•°",
            "å­¦ç”Ÿ": "æ•™è‚²ä¼˜æƒ æ”¿ç­–ï¼Œå­¦ä¹ æ•ˆç‡æå‡ï¼Œåˆ†æœŸä»˜æ¬¾é€‰é¡¹"
        },
        "ç¾å¦†": {
            "å¹´è½»å¥³æ€§": "å°çº¢ä¹¦ç§è‰ï¼Œç¾å¦†åšä¸»è¯•è‰²ï¼Œé™é‡æ¬¾è¥é”€",
            "ä¸­å¹´å¥³æ€§": "æŠ—è€åŠŸæ•ˆå®£ä¼ ï¼Œæ¸©å’Œé…æ–¹ï¼Œå“ç‰Œä¿¡èª‰èƒŒä¹¦"
        }
    }
    
    # è·å–åŸºç¡€ç­–ç•¥
    category_strategies = basic_strategies.get(product_type, basic_strategies["æœè£…"])
    base_strategy = category_strategies.get(target_audience, "é’ˆå¯¹ç›®æ ‡å—ä¼—è¿›è¡Œç²¾å‡†è¥é”€æ¨å¹¿")
    
    # æ ¹æ®é¢„ç®—è°ƒæ•´
    budget_advice = {
        "ä½": "å»ºè®®é‡‡ç”¨æœ‰æœºæµé‡ç­–ç•¥ï¼Œé‡ç‚¹ä¼˜åŒ–å•†å“è¯¦æƒ…é¡µå’Œç”¨æˆ·è¯„ä»·",
        "ä¸­ç­‰": "é€‚å½“æŠ•æ”¾ä¿¡æ¯æµå¹¿å‘Šï¼Œé…åˆè¾¾äººåˆä½œè¿›è¡Œæ¨å¹¿", 
        "é«˜": "å…¨æ¸ é“æŠ•æ”¾ï¼Œå“ç‰Œä»£è¨€äººåˆä½œï¼Œçº¿ä¸‹æ´»åŠ¨é…åˆ"
    }.get(budget, "é€‚å½“æŠ•æ”¾ä¿¡æ¯æµå¹¿å‘Šï¼Œé…åˆè¾¾äººåˆä½œè¿›è¡Œæ¨å¹¿")
    
    return f"""ğŸ“Š **è¥é”€ç­–ç•¥æ–¹æ¡ˆ**

ğŸ¯ **ç›®æ ‡å—ä¼—**: {target_audience}
ğŸ’° **é¢„ç®—æ°´å¹³**: {budget}

ğŸ“‹ **æ ¸å¿ƒç­–ç•¥å»ºè®®**:
{base_strategy}

ğŸ’¡ **é¢„ç®—ç­–ç•¥**:
{budget_advice}

ğŸ“± **æ¨èæ¸ é“**: æ ¹æ®å—ä¼—ç‰¹ç‚¹é€‰æ‹©å°çº¢ä¹¦ã€æŠ–éŸ³ã€Bç«™ç­‰å¹³å°è¿›è¡Œç²¾å‡†æŠ•æ”¾

â° **æ‰§è¡Œå»ºè®®**: 
1. å†…å®¹å‡†å¤‡(1å‘¨) â†’ 2. é¢„çƒ­æ¨å¹¿(2å‘¨) â†’ 3. æ­£å¼æ¨å¹¿(2å‘¨) â†’ 4. æ•ˆæœä¼˜åŒ–(1å‘¨)

æ³¨ï¼šä½¿ç”¨çœŸå®LLMæ¨¡å¼å¯è·å¾—æ›´è¯¦ç»†çš„ä¸ªæ€§åŒ–ç­–ç•¥æ–¹æ¡ˆã€‚"""


@tool
def estimate_ctr(title: str, keywords: List[str] = None) -> Dict[str, Any]:
    """
    ä¼°ç®—æ ‡é¢˜ç‚¹å‡»ç‡å¾—åˆ†ï¼ŒåŸºäºå…³é”®è¯è¦†ç›–ç‡å’Œæ ‡é¢˜è´¨é‡
    
    Args:
        title: å•†å“æ ‡é¢˜
        keywords: æ ¸å¿ƒå…³é”®è¯åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå¦‚æœæœªæä¾›åˆ™ä»æ ‡é¢˜ä¸­è‡ªåŠ¨æå–ï¼‰
        
    Returns:
        åŒ…å«CTRé¢„ä¼°åˆ†æ•°å’Œè¯¦ç»†åˆ†æçš„å­—å…¸
    """
    
    # å¦‚æœæ²¡æœ‰æä¾›å…³é”®è¯ï¼Œä»æ ‡é¢˜ä¸­è‡ªåŠ¨æå–
    if keywords is None or len(keywords) == 0:
        import jieba
        keywords = [k for k in jieba.cut(title) if len(k) > 1 and k not in ['ï¼Œ', 'ã€‚', 'ã€', 'çš„', 'æ˜¯', 'å’Œ', 'ä¸', 'é€‚åˆ']][:5]
    
    target_keywords = keywords
        
    # 1. å…³é”®è¯è¦†ç›–ç‡è®¡ç®—
    title_lower = title.lower()
    covered_keywords = []
    for keyword in target_keywords:
        if keyword.lower() in title_lower:
            covered_keywords.append(keyword)
    
    coverage_rate = len(covered_keywords) / len(target_keywords) if target_keywords else 0
    
    # 2. æ ‡é¢˜é•¿åº¦è¯„åˆ†ï¼ˆ20-30å­—ç¬¦è¾ƒä¼˜ï¼‰
    title_length = len(title)
    if 20 <= title_length <= 30:
        length_score = 1.0
    elif 15 <= title_length <= 35:
        length_score = 0.8
    else:
        length_score = 0.5
    
    # 3. ç‰¹æ®Šç¬¦å·å’Œè¡¨æƒ…è¯„åˆ†
    emoji_pattern = r'[ğŸ”¥ğŸ’¥â­ï¸ğŸ‰ğŸ“±ğŸ’]'
    bracket_pattern = r'[ã€ã€‘\[\]ï¼ˆï¼‰()]'
    
    has_emoji = len(re.findall(emoji_pattern, title)) > 0
    has_brackets = len(re.findall(bracket_pattern, title)) > 0
    
    symbol_score = 0.7
    if has_emoji:
        symbol_score += 0.15
    if has_brackets:
        symbol_score += 0.15
    symbol_score = min(symbol_score, 1.0)
    
    # 4. ç´§æ€¥è¯æ±‡è¯„åˆ†
    urgent_words = ['é™æ—¶', 'æŠ¢è´­', 'ç‰¹æƒ ', 'æ–°å“', 'çˆ†æ¬¾', 'çƒ­é”€']
    urgent_count = sum(1 for word in urgent_words if word in title)
    urgent_score = min(urgent_count * 0.2, 0.6)
    
    # 5. ç»¼åˆCTRè¯„åˆ†
    base_score = 0.4  # åŸºç¡€åˆ†
    keyword_weight = 0.3
    length_weight = 0.1  
    symbol_weight = 0.1
    urgent_weight = 0.1
    
    ctr_score = (base_score + 
                coverage_rate * keyword_weight + 
                length_score * length_weight +
                symbol_score * symbol_weight +
                urgent_score * urgent_weight)
    
    ctr_score = min(ctr_score, 1.0)
    ctr_percentage = round(ctr_score * 100, 1)
    
    return {
        "ctr_score": round(ctr_score, 3),
        "ctr_percentage": f"{ctr_percentage}%",
        "coverage_rate": round(coverage_rate, 3),
        "covered_keywords": covered_keywords,
        "length_score": round(length_score, 3),
        "title_length": title_length,
        "has_emoji": has_emoji,
        "has_brackets": has_brackets,
        "urgent_words_count": urgent_count,
        "recommendations": get_optimization_suggestions(coverage_rate, length_score, has_emoji, has_brackets, urgent_count)
    }


def get_optimization_suggestions(coverage_rate: float, length_score: float, 
                               has_emoji: bool, has_brackets: bool, urgent_count: int) -> List[str]:
    """
    æ ¹æ®è¯„åˆ†æƒ…å†µæä¾›ä¼˜åŒ–å»ºè®®
    """
    suggestions = []
    
    if coverage_rate < 0.6:
        suggestions.append("å»ºè®®å¢åŠ æ›´å¤šç›®æ ‡å…³é”®è¯ä»¥æå‡æœç´¢åŒ¹é…åº¦")
    
    if length_score < 0.8:
        suggestions.append("æ ‡é¢˜é•¿åº¦å»ºè®®æ§åˆ¶åœ¨20-30å­—ç¬¦ä¹‹é—´")
        
    if not has_emoji:
        suggestions.append("å¯ä»¥é€‚å½“æ·»åŠ è¡¨æƒ…ç¬¦å·å¢åŠ æ ‡é¢˜å¸å¼•åŠ›")
        
    if not has_brackets:
        suggestions.append("ä½¿ç”¨ã€ã€‘ç­‰æ‹¬å·çªå‡ºé‡ç‚¹ä¿¡æ¯")
        
    if urgent_count == 0:
        suggestions.append("æ·»åŠ 'é™æ—¶'ã€'ç‰¹æƒ 'ç­‰ç´§æ€¥è¯æ±‡æå‡ç‚¹å‡»æ¬²æœ›")
        
    if not suggestions:
        suggestions.append("æ ‡é¢˜è´¨é‡è‰¯å¥½ï¼Œå¯è€ƒè™‘A/Bæµ‹è¯•ä¸åŒç‰ˆæœ¬")
        
    return suggestions


@tool
def analyze_competitor_title(competitor_title: str, our_keywords: List[str] = None) -> Dict[str, Any]:
    """
    åˆ†æç«å“æ ‡é¢˜ï¼Œæä¾›å·®å¼‚åŒ–å»ºè®®
    
    Args:
        competitor_title: ç«å“æ ‡é¢˜
        our_keywords: æˆ‘ä»¬çš„æ ¸å¿ƒå…³é”®è¯ï¼ˆå¯é€‰ï¼Œå¦‚æœæœªæä¾›åˆ™ä»ç«å“æ ‡é¢˜ä¸­æ¨æ–­ï¼‰
        
    Returns:
        ç«å“åˆ†æç»“æœå’Œå·®å¼‚åŒ–å»ºè®®
    """
    
    # åˆ†æç«å“æ ‡é¢˜çš„å…³é”®è¯
    competitor_keywords = list(jieba.cut(competitor_title))
    competitor_keywords = [k for k in competitor_keywords if len(k) > 1]
    
    # å¦‚æœæ²¡æœ‰æä¾›æˆ‘ä»¬çš„å…³é”®è¯ï¼Œä»ç«å“æ ‡é¢˜ä¸­æ¨æ–­ç›¸å…³å…³é”®è¯
    if our_keywords is None or len(our_keywords) == 0:
        # åŸºäºç«å“æ ‡é¢˜æ¨æ–­å¯èƒ½çš„å…³é”®è¯
        our_keywords = competitor_keywords[:3]  # ä½¿ç”¨ç«å“æ ‡é¢˜çš„å‰3ä¸ªå…³é”®è¯ä½œä¸ºå‚è€ƒ
    
    # æ‰¾å‡ºå…±åŒå…³é”®è¯å’Œå·®å¼‚å…³é”®è¯
    common_keywords = list(set(our_keywords) & set(competitor_keywords))
    unique_to_competitor = list(set(competitor_keywords) - set(our_keywords))
    unique_to_us = list(set(our_keywords) - set(competitor_keywords))
    
    # è·å–ç«å“æ ‡é¢˜CTRè¯„ä¼°
    competitor_ctr = estimate_ctr.invoke({
        "title": competitor_title,
        "keywords": competitor_keywords
    })
    
    # ç”Ÿæˆå·®å¼‚åŒ–å»ºè®®
    differentiation_suggestions = []
    
    if unique_to_competitor:
        differentiation_suggestions.append(f"ç«å“å¼ºè°ƒäº†ï¼š{', '.join(unique_to_competitor[:3])}ï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘çªå‡ºå…¶ä»–å–ç‚¹")
    
    if unique_to_us:
        differentiation_suggestions.append(f"æˆ‘ä»¬çš„ä¼˜åŠ¿å…³é”®è¯ï¼š{', '.join(unique_to_us[:3])}ï¼Œåº”è¯¥é‡ç‚¹çªå‡º")
    
    if competitor_ctr["ctr_score"] > 0.7:
        differentiation_suggestions.append("ç«å“æ ‡é¢˜è´¨é‡è¾ƒé«˜ï¼Œå»ºè®®å­¦ä¹ å…¶æ ‡é¢˜ç»“æ„ä½†è¦çªå‡ºå·®å¼‚åŒ–")
    else:
        differentiation_suggestions.append("ç«å“æ ‡é¢˜æœ‰ä¼˜åŒ–ç©ºé—´ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šæå‡")
    
    return {
        "competitor_title": competitor_title,
        "competitor_ctr_analysis": competitor_ctr,
        "common_keywords": common_keywords,
        "competitor_unique_keywords": unique_to_competitor,
        "our_unique_keywords": unique_to_us,
        "differentiation_suggestions": differentiation_suggestions
    }