# 生产环境部署指南

## 快速开始

### 1. 系统要求
- **操作系统**: Windows 10/11, macOS, Linux
- **Python**: 3.8+ (推荐 3.9-3.11)
- **内存**: 至少 8GB (推荐 16GB)
- **存储**: 至少 10GB 可用空间
- **网络**: 用于下载模型文件

### 2. 环境准备

#### 安装Python依赖
```bash
cd merchant-assistant
pip install -r requirements.txt
```

#### 安装Ollama (可选，用于真实LLM)
- 访问 [https://ollama.ai](https://ollama.ai) 下载安装
- 下载Qwen模型: `ollama pull qwen2.5:7b`

### 3. 配置升级

#### 自动配置 (推荐)
```bash
cd merchant-assistant
python update_knowledge_base.py
```

#### 手动配置
修改 `config.py`:
```python
# 设置为生产模式
Config.set_production_mode()
```

### 4. 启动系统
```bash
# 方式1: 使用启动脚本
python start.py

# 方式2: 直接启动Web界面
cd ui
streamlit run streamlit_app.py
```

## 详细配置说明

### LLM模型配置

#### 模拟模式 (默认)
- **优点**: 无需额外配置，快速启动
- **缺点**: 回复相对简单，智能程度有限
- **适用**: 演示、测试、资源受限环境

#### Ollama + Qwen模式 (推荐)
- **优点**: 智能程度高，中文优化，本地部署
- **缺点**: 需要下载模型，占用内存较多
- **适用**: 生产环境，对智能程度有要求

配置示例:
```python
# config.py
LLM_CONFIGS = {
    "ollama_qwen": {
        "type": "ollama",
        "model_name": "qwen2.5:7b",  # 或 qwen2.5:14b
        "base_url": "http://localhost:11434",
        "temperature": 0.7
    }
}
```

### Embedding模型配置

#### 中文模型 (推荐)
```python
EMBEDDING_CONFIGS = {
    "sentence_transformers": {
        "type": "sentence_transformers",
        "model_name": "shibing624/text2vec-base-chinese",
        "device": "cpu"  # 或 "cuda" 如果有GPU
    }
}
```

#### 大型模型 (高精度)
```python
"sentence_transformers_large": {
    "type": "sentence_transformers", 
    "model_name": "BAAI/bge-large-zh-v1.5",
    "device": "cpu"
}
```

### 知识库扩展

#### 添加文档
1. 将 `.md` 或 `.txt` 文件放入 `knowledge/` 目录
2. 运行重建脚本:
```bash
python update_knowledge_base.py
```

#### 当前知识库内容
- `merchant_operation_guide.md` - 商家运营指南
- `title_templates.md` - 标题模板
- `platform_rules.md` - 平台规则
- `advanced_marketing_strategies.md` - 高级营销策略
- `customer_psychology.md` - 消费者心理学
- `data_analysis_guide.md` - 数据分析指南

## 性能优化

### 硬件优化

#### CPU优化
- 推荐多核心CPU (4核心以上)
- 优化进程数: `export OMP_NUM_THREADS=4`

#### 内存优化
- 7B模型需要约8GB内存
- 14B模型需要约16GB内存
- 为系统预留4GB内存

#### GPU加速 (可选)
```bash
# 安装CUDA版本
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 配置GPU设备
# config.py 中设置 device: "cuda"
```

### 软件优化

#### 缓存配置
```python
# 启用模型缓存
os.environ["TRANSFORMERS_CACHE"] = "./models_cache"
os.environ["HF_HOME"] = "./huggingface_cache"
```

#### 并发配置
```python
# Streamlit配置
# .streamlit/config.toml
[server]
maxUploadSize = 200
enableCORS = false
enableXsrfProtection = false

[runner]
magicEnabled = false
```

## 监控与维护

### 日志配置
```python
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('merchant_assistant.log'),
        logging.StreamHandler()
    ]
)
```

### 性能监控
- **内存使用**: 监控模型加载内存
- **响应时间**: 监控API和Web界面响应
- **错误率**: 监控异常和失败请求
- **用户活跃度**: 监控系统使用情况

### 定期维护
- **每周**: 检查日志文件，清理临时文件
- **每月**: 更新依赖包，优化知识库
- **每季度**: 评估模型性能，考虑升级

## 安全配置

### 网络安全
```python
# 限制访问IP
# .streamlit/config.toml
[server]
address = "127.0.0.1"  # 仅本地访问
# address = "0.0.0.0"  # 允许外部访问 (需要防火墙保护)
```

### 数据安全
- **敏感信息**: 不要在知识库中存储敏感数据
- **访问控制**: 设置合适的文件权限
- **备份策略**: 定期备份知识库和配置文件

### API安全
```python
# 添加简单的API密钥验证 (如需要)
API_KEY = os.getenv("MERCHANT_ASSISTANT_API_KEY")
```

## 故障排除

### 常见问题

#### 1. 模型下载失败
```bash
# 手动下载模型
export HF_ENDPOINT=https://hf-mirror.com  # 使用国内镜像
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('shibing624/text2vec-base-chinese')"
```

#### 2. 内存不足
- 使用更小的模型 (qwen2.5:1.5b)
- 减少并发用户数
- 增加虚拟内存

#### 3. Ollama连接失败
```bash
# 检查Ollama服务
curl http://localhost:11434/api/tags

# 重启Ollama服务
ollama serve
```

#### 4. Web界面启动失败
```bash
# 检查端口占用
netstat -ano | findstr :8501

# 使用其他端口
streamlit run streamlit_app.py --server.port 8502
```

### 日志分析
```bash
# 查看错误日志
tail -f merchant_assistant.log | grep ERROR

# 查看性能日志
tail -f merchant_assistant.log | grep "处理时间"
```

## 扩展开发

### 添加新工具
1. 在 `agent/tools/` 目录创建新工具
2. 使用 `@tool` 装饰器定义工具函数
3. 在 `agent_executor.py` 中注册工具

### 自定义知识库
1. 创建专业领域文档
2. 使用专业词汇和术语
3. 定期更新和维护内容

### API接口开发
```python
# 创建 FastAPI 接口 (可选)
from fastapi import FastAPI
from agent.agent_executor import MerchantAssistantAgent

app = FastAPI()
assistant = MerchantAssistantAgent()

@app.post("/chat")
async def chat(query: str):
    result = assistant.process_request(query)
    return result
```

## 部署建议

### 开发环境
- 使用模拟模式快速开发
- 频繁重启测试
- 详细日志记录

### 测试环境
- 使用真实模型测试功能
- 模拟生产环境配置
- 性能和稳定性测试

### 生产环境
- 使用最优配置
- 监控和告警
- 定期备份和维护
- 负载均衡和高可用

通过以上配置，您的商家智能助手系统将具备生产环境运行的能力！